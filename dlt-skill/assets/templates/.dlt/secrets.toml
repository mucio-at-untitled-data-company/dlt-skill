# dlt Secrets File
#
# IMPORTANT: This file contains sensitive credentials. Never commit to version control!
# Add .dlt/secrets.toml to your .gitignore file.
#
# Secret names must match the parameter names in your source functions.
# Structure: [sources.<source_name>] for source secrets
#            [destination.<destination_name>] for destination secrets
#
# Connection strings can be placed at the top of the file, before any section headers.

# ============================================================================
# DESTINATION CREDENTIALS
# ============================================================================

# ----------------------------------------------------------------------------
# PostgreSQL
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/postgres
# ----------------------------------------------------------------------------
# [destination.postgres.credentials]
# database = "dlt_data"
# username = "loader"
# password = "your_password"
# host = "localhost"
# port = 5432
# connect_timeout = 15
#
# # Or use connection string (place at top of file, before sections):
# # destination.postgres.credentials = "postgresql://loader:password@localhost:5432/dlt_data?connect_timeout=15"

# ----------------------------------------------------------------------------
# Google BigQuery
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/bigquery
# ----------------------------------------------------------------------------
# Service Account Authentication:
# [destination.bigquery]
# location = "US"
#
# [destination.bigquery.credentials]
# project_id = "your_project_id"
# private_key = "-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n"
# client_email = "service-account@project.iam.gserviceaccount.com"
#
# OAuth 2.0 Authentication:
# [destination.bigquery.credentials]
# project_id = "your_project_id"
# client_id = "your_client_id"
# client_secret = "your_client_secret"
# refresh_token = "your_refresh_token"
#
# Default credentials (uses GOOGLE_APPLICATION_CREDENTIALS env var):
# [destination.bigquery]
# location = "US"

# ----------------------------------------------------------------------------
# Snowflake
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/snowflake
# ----------------------------------------------------------------------------
# Password Authentication:
# [destination.snowflake.credentials]
# database = "DLT_DATA"
# username = "loader"
# password = "your_password"
# host = "account_id.region.snowflakecomputing.com"  # Account Identifier
# warehouse = "COMPUTE_WH"
# role = "DLT_LOADER_ROLE"
#
# Key Pair Authentication:
# [destination.snowflake.credentials]
# database = "DLT_DATA"
# username = "loader"
# host = "account_id.region.snowflakecomputing.com"
# private_key = "LS0tLS1CRUdJTiBFTkNSWVBURUQgUFJJ....Qo="  # Base64-encoded
# private_key_passphrase = "your_passphrase"
# # Or use file path:
# # private_key_path = "/path/to/private_key.pem"
#
# OAuth Authentication:
# [destination.snowflake.credentials]
# database = "DLT_DATA"
# username = "loader"
# authenticator = "oauth"
# token = "your_oauth_token"
#
# Connection string (place at top of file):
# destination.snowflake.credentials = "snowflake://loader:password@account_id/DLT_DATA?warehouse=COMPUTE_WH&role=DLT_LOADER_ROLE"

# ----------------------------------------------------------------------------
# Amazon Redshift
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/redshift
# ----------------------------------------------------------------------------
# [destination.redshift.credentials]
# database = "your_database"
# username = "your_username"
# password = "your_password"
# host = "cluster-name.xxxxx.region.redshift.amazonaws.com"
# port = 5439
# connect_timeout = 15
#
# Connection string (place at top of file):
# destination.redshift.credentials = "redshift://loader:password@cluster.region.redshift.amazonaws.com:5439/database?connect_timeout=15"

# ----------------------------------------------------------------------------
# Databricks
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/databricks
# ----------------------------------------------------------------------------
# OAuth2 Authentication:
# [destination.databricks.credentials]
# server_hostname = "your_workspace.azuredatabricks.net"
# http_path = "/sql/1.0/warehouses/your_warehouse_id"
# catalog = "your_catalog"
# client_id = "your_client_id"
# client_secret = "your_client_secret"
#
# Access Token Authentication:
# [destination.databricks.credentials]
# server_hostname = "your_workspace.azuredatabricks.net"
# http_path = "/sql/1.0/warehouses/your_warehouse_id"
# catalog = "your_catalog"
# access_token = "your_access_token"

# ----------------------------------------------------------------------------
# ClickHouse
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/clickhouse
# ----------------------------------------------------------------------------
# [destination.clickhouse.credentials]
# database = "dlt"
# username = "default"
# password = "your_password"
# host = "localhost"
# port = 9000
# http_port = 8443  # Required for non-staged loading
# secure = 1        # Use TLS
#
# Connection string (place at top of file):
# destination.clickhouse.credentials = "clickhouse://user:password@localhost:9000/database?secure=1"

# ----------------------------------------------------------------------------
# Microsoft SQL Server
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/mssql
# ----------------------------------------------------------------------------
# [destination.mssql.credentials]
# database = "dlt_data"
# username = "loader"
# password = "your_password"
# host = "server.database.windows.net"
# port = 1433
# connect_timeout = 15
#
# [destination.mssql.credentials.query]
# TrustServerCertificate = "yes"
# Encrypt = "yes"
# LongAsMax = "yes"
#
# Windows Authentication:
# destination.mssql.credentials = "mssql://server.database.windows.net/dlt_data?trusted_connection=yes"

# ----------------------------------------------------------------------------
# Azure Synapse
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/synapse
# ----------------------------------------------------------------------------
# [destination.synapse.credentials]
# database = "your_pool"
# username = "loader"
# password = "your_password"
# host = "workspace_name.sql.azuresynapse.net"
# port = 1433
# connect_timeout = 15
#
# Connection string (place at top of file):
# destination.synapse.credentials = "synapse://loader:password@workspace.sql.azuresynapse.net:1433/pool?connect_timeout=15"

# ----------------------------------------------------------------------------
# AWS Athena (requires filesystem staging)
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/athena
# ----------------------------------------------------------------------------
# [destination.filesystem]
# bucket_url = "s3://your-data-bucket"
#
# [destination.filesystem.credentials]
# aws_access_key_id = "your_access_key"
# aws_secret_access_key = "your_secret_key"
# # Or use profile: profile_name = "your-profile"
#
# [destination.athena]
# query_result_bucket = "s3://your-results-bucket"
# region_name = "us-east-1"
#
# [destination.athena.credentials]
# aws_access_key_id = "your_access_key"
# aws_secret_access_key = "your_secret_key"

# ----------------------------------------------------------------------------
# Filesystem / Cloud Storage
# Docs: https://dlthub.com/docs/dlt-ecosystem/destinations/filesystem
# ----------------------------------------------------------------------------
# AWS S3:
# [destination.filesystem]
# bucket_url = "s3://your-bucket-name"
#
# [destination.filesystem.credentials]
# aws_access_key_id = "your_access_key"
# aws_secret_access_key = "your_secret_key"
# # Or use profile: profile_name = "your-profile"
#
# Google Cloud Storage:
# [destination.filesystem]
# bucket_url = "gs://your-bucket-name"
#
# [destination.filesystem.credentials]
# project_id = "your_project_id"
# private_key = "-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n"
# client_email = "service-account@project.iam.gserviceaccount.com"
#
# Azure Blob Storage:
# [destination.filesystem]
# bucket_url = "az://container-name/path"
#
# [destination.filesystem.credentials]
# azure_storage_account_name = "your_account_name"
# azure_storage_account_key = "your_account_key"
# # Or use SAS token:
# # azure_storage_sas_token = "your_sas_token"
# # Or use service principal:
# # azure_client_id = "your_client_id"
# # azure_client_secret = "your_client_secret"
# # azure_tenant_id = "your_tenant_id"

# ----------------------------------------------------------------------------
# DuckDB
# Note: DuckDB does not require secrets - configure the file path in
# config.toml or pass it directly to dlt.pipeline(destination="duckdb://path/to/file.duckdb")
# ----------------------------------------------------------------------------

# ============================================================================
# SOURCE CREDENTIALS
# ============================================================================

# ----------------------------------------------------------------------------
# SQL Database Sources (PostgreSQL, MySQL, MSSQL, etc.)
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/sql_database
# ----------------------------------------------------------------------------
# [sources.sql_database.credentials]
# drivername = "postgresql"  # postgresql, mysql+pymysql, mssql+pyodbc
# database = "source_db"
# username = "reader"
# password = "your_password"
# host = "localhost"
# port = 5432
#
# Or use connection string:
# [sources.sql_database]
# credentials = "postgresql://reader:password@localhost:5432/source_db"
# credentials = "mysql+pymysql://reader:password@localhost:3306/source_db"
# credentials = "mssql+pyodbc://reader:password@server/database?driver=ODBC+Driver+17+for+SQL+Server"

# ----------------------------------------------------------------------------
# MongoDB
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/mongodb
# ----------------------------------------------------------------------------
# [sources.mongodb]
# connection_url = "mongodb://user:password@host:27017"
# # For MongoDB Atlas:
# # connection_url = "mongodb+srv://user:password@cluster.mongodb.net"

# ----------------------------------------------------------------------------
# Salesforce
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/salesforce
# ----------------------------------------------------------------------------
# [sources.salesforce]
# user_name = "user@company.com"
# password = "your_password"
# security_token = "your_security_token"  # Reset in Salesforce settings to get this

# ----------------------------------------------------------------------------
# HubSpot
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/hubspot
# ----------------------------------------------------------------------------
# [sources.hubspot]
# api_key = "your_private_app_access_token"  # API keys deprecated Nov 2022

# ----------------------------------------------------------------------------
# GitHub
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/github
# ----------------------------------------------------------------------------
# [sources.github]
# access_token = "ghp_your_personal_access_token"
# # Scopes needed: public_repo, read:repo_hook, read:org, read:user, read:project, read:discussion

# ----------------------------------------------------------------------------
# Stripe
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/stripe
# ----------------------------------------------------------------------------
# [sources.stripe_analytics]
# stripe_secret_key = "sk_live_your_stripe_secret_key"

# ----------------------------------------------------------------------------
# Zendesk
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/zendesk
# ----------------------------------------------------------------------------
# Email + Password Authentication:
# [sources.zendesk.credentials]
# subdomain = "your_company"
# email = "user@company.com"
# password = "your_password"
#
# Email + API Token Authentication:
# [sources.zendesk.credentials]
# subdomain = "your_company"
# email = "user@company.com"
# token = "your_api_token"  # Generate in Admin Center > Apps > Zendesk API
#
# OAuth Authentication:
# [sources.zendesk.credentials]
# subdomain = "your_company"
# oauth_token = "your_oauth_token"

# ----------------------------------------------------------------------------
# REST API (Generic)
# Docs: https://dlthub.com/docs/dlt-ecosystem/verified-sources/rest_api
# ----------------------------------------------------------------------------
# [sources.rest_api]
# api_token = "your_bearer_token"
#
# # Or for OAuth:
# [sources.rest_api]
# client_id = "your_client_id"
# client_secret = "your_client_secret"
# access_token_url = "https://auth.example.com/oauth/token"
